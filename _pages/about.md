---
layout: about
title: Yuanpeng Chen 
permalink: /
lang: en
keywords:
  - Yuanpeng Chen
  - Vision-Language-Action
  - Autonomous Driving

profile:
  align: right
  image: portrait.jpeg
  image_circular: true # crops the image to make it circular
  more_info: >
    <p>Email: chenyuanpengcyp@gmail.com</p>
    <p>WeChat: chenyuanpeng24</p>
    <p>Shanghai, China</p>

selected_papers: false # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: false # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: false
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

## ðŸ”­ About Me

Iâ€™m **Yuanpeng Chen**, a senior algorithm expert and team leader specializing in architecting and deploying production-ready autonomous driving systems. My work focuses on bridging the gap between frontier research in End-to-End architectures, Vision-Language-Action (VLA) models, and World Models, and the rigorous demands of mass production. I specialize in the full lifecycle of algorithm development, from conceptual design and team leadership to hands-on optimization of large model inference engines on automotive-grade hardware.

My career has been a progression of increasing responsibility, from foundational research on neural network efficiency to leading a core vision team from scratch (0 to 1). I have a proven track record of delivering state-of-the-art systems, including BEV perception solutions that are now running on production vehicles.

> My mission is to build true embodied intelligence for the physical world, using autonomous driving as the proving ground. I focus on creating AI systems that develop a causal and predictive understanding of their environment, enabling them to anticipate and navigate the complexities of real-world interactions safely and intuitively.

### Key Highlights

- **Production-First Architecture**: Architected FastBEV++, a state-of-the-art BEV perception framework designed for deployment. Achieved real-time performance (10 FPS) on low-power automotive SoCs and pioneered a "OneModel" cross-platform deployment strategy that requires no custom operators.
- **End-to-End System Development (0 to 1)**: Architected and led the full R&D lifecycle of a unified End-to-End perception system, taking it from initial concept to a production-validated framework.
- **Award-Winning VLM Application**: Led my team to win First Prize at the PRCV 2024 DriveLM Challenge by building an advanced decision-making system leveraging InternVL-6B, LoRA, and RLHF techniques.
- **Hardware-Aware Performance Optimization**: Achieved up to 2x inference acceleration on low-power automotive SoCs (e.g., MTK8665) using advanced quantization-aware training (QAT), demonstrating deep expertise in model deployment.


## ðŸŒŸ Research Interests

- **Autonomous Driving:**: Vision-Language-Action (VLA) models, End-to-End Driving Systems
- **World Models & Simulation**: Dynamic scene understanding, generative simulation, and reinforcement learning at scale 
- **Deployable AI**: Large Model Inference Engine optimization, model compression, and bridging the gap between algorithmic performance and on-vehicle deployment 


## ðŸ“š Academic Achievements

1. **FastBEV++: Fast by Algorithm, Deployable by Design** (arXiv 2025)
   Y. Chen, H. Song, W. Tao, S. Mo, S. Zhang, X. Hua, T. Zhao. arXiv:2512.08237
2. **Precise Drive with VLM: First Prize Solution for PRCV 2024 Drive LM challenge** 
   B. Huang, S. Wang, Y. Chen, Y. Wu, H. Song, Z. Ding, et al.
3. **RTN: Reparameterized Ternary Network** (AAAI 2020)  
   Y. Li, X. Dong, S. Q. Zhang, H. Bai, Y. Chen, W. Wang
