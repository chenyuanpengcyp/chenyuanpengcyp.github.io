---
layout: about
title: about
permalink: /
subtitle: Cognitive Intelligence Lead at <a href='https://www.lixiang.com/'>Li Auto</a> | Autonomous Driving Expert | AI Researcher

profile:
  align: right
  image: portrait.jpeg
  image_circular: true # crops the image to make it circular
  more_info: >
    <p>Email: zk_1028@aliyun.com</p>
    <p>WeChat: KevinZhan1990</p>
    <p>Beijing, China</p>

selected_papers: false # includes a list of papers marked as "selected={true}"
social: false # includes social icons at the bottom of the page

announcements:
  enabled: false # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: false
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

[![Google Scholar](https://img.shields.io/badge/Google%20Scholar-4285F4?style=flat&logo=google-scholar&logoColor=white)](https://scholar.google.com/citations?user=1J061HIAAAAJ&hl=en)
[![Email](https://img.shields.io/badge/Email-zk__1028%40aliyun.com-D14836?style=flat&logo=gmail&logoColor=white)](mailto:zk_1028@aliyun.com)
[![Contact](https://img.shields.io/badge/Contact-Available%20on%20Request-25D366?style=flat&logo=whatsapp&logoColor=white)](mailto:zk_1028@aliyun.com)

## ðŸ”­ About Me

I am **Kun Zhan**, Cognitive Intelligence Lead at Li Auto and Site Manager of the companyâ€™s new U.S. R&D Center.

At Li Auto, I own the Vision-Language-Action (VLA) algorithm roadmapâ€”directing perception, planning, large-scale model training, and vehicle-grade deployment. My work has advanced from end-to-end driving (E2E) and vision-language models (VLM) to the full VLA stack, and I lead world-model research that powers end-to-end simulation, synthetic-data generation, and reinforcement learning.

My mission is to close the gap between breakthrough AI and everyday mobility. By translating cutting-edge computer vision, 3D perception, multimodal foundation models, and reinforcement learning into production vehicles and robots, I strive to deliver safer, smarter, truly autonomous transportation.

## ðŸŒŸ Research Interests

- **Autonomous Driving**: Vision-Language-Action(VLA) Model, End-to-end autonomous driving systems, decision-making and planning
- **Computer Vision**: Object detection and tracking, scene understanding
- **3D Vision**: 3D perception, reconstruction, and modeling
- **Large Language Models**: Applications of multimodal large models in autonomous driving
- **World Models**: Environment modeling and prediction, reinforcement learning

## ðŸ’¼ Work Experience

### **Li Auto**â€‚|â€‚Apr 2021 â€“ Present
**Cognitive Intelligence Lead & VLA Algorithm Owner**
- Direct a more than 100-person org covering perception, planning, foundation-model training, and on-vehicle inference.
- Delivered three generations of AI stacks (E2E â†’ VLM â†’ VLA) into mass-production pipelines.
- Established and lead a dedicated world-model group for reinforcement learning and closed-loop simulation.
- Previously headed the Prediction, Static BEV, Driving Perception, and Large-Model teams. 

**Site Manager, U.S. R&D Center (San Jose, CA)**
- Built Li Autoâ€™s overseas research hub.
- Own local strategy, budgeting, and cross-border collaboration with Beijing HQ, accelerating global talent acquisition and technology transfer.

### **Baidu L4 Team**â€‚|â€‚Apr 2016 â€“ Mar 2021
**Autonomous-Driving Engineering**
- Served as Algorithm Lead for Prediction; designed L4 prediction pre-decision algorithms for robo-taxi operations.
- Developed planning-and-control (PnC) algorithms and deep-learning onboard modules for L4 pilots.

## ðŸ“š Academic Achievements

### Citation Statistics
- Top Papers: 32
- Total Citations: 677
- h-index: 10
- i10-index: 10

### Selected Publications

1. **Drivevlm: The convergence of autonomous driving and large vision-language models** (2024)
   X Tian, J Gu, B Li, Y Liu, Y Wang, Z Zhao, **K Zhan**, P Jia, X Lang, H Zhao
   *arXiv preprint arXiv:2402.12289* | Citations: 255

2. **Street gaussians: Modeling dynamic urban scenes with gaussian splatting** (2024)
   Y Yan, H Lin, C Zhou, W Wang, H Sun, **K Zhan**, X Lang, X Zhou, S Peng
   *European Conference on Computer Vision, 156-173* | Citations: 211

3. **Planagent: A multi-modal large language agent for closed-loop vehicle motion planning** (2024)
   Y Zheng, Z Xing, Q Zhang, B Jin, P Li, Y Zheng, Z Xia, **K Zhan**, X Lang, D Zhao
   *arXiv preprint arXiv:2406.01587* | Citations: 31

4. **Unleashing generalization of end-to-end autonomous driving with controllable long video generation** (2024)
   E Ma, L Zhou, T Tang, Z Zhang, D Han, J Jiang, **K Zhan**, P Jia, X Lang, K Yu
   *arXiv preprint arXiv:2406.01349* | Citations: 27

5. **Tod3cap: Towards 3d dense captioning in outdoor scenes** (2024)
   B Jin, Y Zheng, P Li, W Li, Y Zheng, S Hu, X Liu, J Zhu, Z Yan, H Sun, **K Zhan**, X Lang, P Jia
   *European Conference on Computer Vision, 367-384* | Citations: 22

### Patents
- 16 Chinese Patents
- 2 US Patents

### Academic Service
- **Program Committee/Reviewer**: CVPR, ICCV, ECCV, NeurIPS, AAAI
- **Journal Reviewer**: IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), IEEE Transactions on Intelligent Transportation Systems (T-ITS), IEEE Transactions on Intelligent Vehicles (T-IV)
- **Workshop Organizer**: Autonomous Driving Workshop at CVPR 2023
